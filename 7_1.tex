\section*{7.1 Inferência Estatística}

Lembre-se de nossos vários exemplos de ensaios clínicos. O que poderíamos dizer sobre a probabilidade de um futuro paciente responder com sucesso ao tratamento depois de observarmos os resultados de uma coleção de outros pacientes? Essa é a questão que a inferência estatística se destina a abordar. Em geral, a inferência estatística consiste em fazer declarações probabilísticas sobre quantidades desconhecidas. Por exemplo, podemos calcular médias, variâncias, quantis e algumas outras quantidades que ainda serão introduzidas sobre variáveis aleatórias não observadas e parâmetros desconhecidos de distribuições. Nosso objetivo será dizer o que aprendemos sobre as quantidades desconhecidas após observar alguns dados que acreditamos conter informações relevantes. Aqui estão alguns outros exemplos de questões que a inferência estatística pode tentar responder. O que podemos dizer sobre se uma máquina está funcionando corretamente após observarmos parte de sua produção? Em um processo cível, o que podemos dizer sobre se houve discriminação após observar como diferentes grupos étnicos foram tratados? Os métodos de inferência estatística, que desenvolveremos para abordar essas questões, são construídos sobre a teoria da probabilidade abordada nos capítulos anteriores deste texto.

\subsection*{Probabilidade e Modelos Estatísticos}

Nos capítulos anteriores deste livro, discutimos a teoria e os métodos da probabilidade. À medida que novos conceitos em probabilidade eram introduzidos, também introduzimos exemplos do uso desses conceitos em problemas que agora reconheceremos como \textit{inferência estatística}. Antes de discutir a inferência estatística formalmente, é útil nos recordarmos daqueles conceitos de probabilidade que fundamentarão a inferência.

\vspace{1cm} % Espaçamento para o exemplo

\noindent\textbf{Exemplo 7.1.1} \quad \textbf{Tempo de Vida de Componentes Eletrônicos.} Uma empresa vende componentes eletrônicos e está interessada em saber por quanto tempo cada componente provavelmente durará. Eles podem coletar dados sobre componentes que foram usados sob condições típicas. Eles optam por usar a família de distribuições exponenciais para modelar o tempo (em anos) desde o momento em que um componente é colocado em serviço até sua falha. Eles gostariam de modelar os componentes como tendo todos a mesma taxa de falha $\theta$, mas há incerteza sobre o valor numérico específico de $\theta$. Para ser mais preciso,
seja $X_1, X_2, \dots$ uma sequência de tempos de vida de componentes em anos. A empresa acredita que, se soubessem a taxa de falha $\theta$, então $X_1, X_2, \dots$ seriam variáveis aleatórias i.i.d. (independentes e identicamente distribuídas) com distribuição exponencial com parâmetro $\theta$. (Ver Seção 5.7 para a definição de distribuições exponenciais. Estamos usando o símbolo $\theta$ para o parâmetro de nossas distribuições exponenciais em vez de $\beta$ para corresponder ao restante da notação neste capítulo.) Suponha que os dados que a empresa irá observar consistam nos valores de $X_1, \dots, X_m$, mas que eles ainda estejam interessados em $X_{m+1}, X_{m+2}, \dots$. Eles também estão interessados em $\theta$ porque está relacionado ao tempo de vida médio. Como vimos na Eq. (5.7.17), a média de uma variável aleatória exponencial com parâmetro $\theta$ é $1/\theta$, razão pela qual a empresa pensa em $\theta$ como a taxa de falha.

Imaginamos um experimento cujos resultados são sequências de tempos de vida como descrito acima. Como mencionado, se soubéssemos o valor de $\theta$, então $X_1, X_2, \dots$ seriam variáveis aleatórias i.i.d. Nesse caso, a lei dos grandes números (Teorema 6.2.4) diz que a média $\frac{1}{n}\sum_{i=1}^{n}X_i$ converge em probabilidade para a média $1/\theta$. E o Teorema 6.2.5 diz que $n/\sum_{i=1}^{n}X_i$ converge em probabilidade para $\theta$. Como $\theta$ é uma função da sequência de tempos de vida que constituem cada resultado experimental, ele pode ser tratado como uma variável aleatória. Suponha que, antes de observar os dados, a empresa acredite que a taxa de falha é provavelmente em torno de 0,5/ano, mas há uma certa incerteza sobre isso. Eles modelam $\theta$ como uma variável aleatória com distribuição gama com parâmetros 1 e 2. Parafraseando o que foi dito anteriormente, eles também modelam $X_1, X_2, \dots$ como variáveis aleatórias exponenciais condicionalmente i.i.d. com parâmetro $\theta$ dado $\theta$. Eles esperam aprender mais sobre $\theta$ examinando os dados da amostra $X_1, \dots, X_m$. Eles nunca podem aprender $\theta$ precisamente, pois isso exigiria observar toda a sequência infinita $X_1, X_2, \dots$. Por essa razão, $\theta$ é apenas hipoteticamente observável.

\vspace{1cm}
O Exemplo 7.1.1 ilustra várias características que serão comuns à maioria dos problemas de inferência estatística e que constituem o que chamamos de modelo estatístico.
\vspace{1cm}

\noindent\textbf{Definição 7.1.1} \quad \textbf{Modelo Estatístico.} Um \textit{modelo estatístico} consiste em uma identificação das variáveis aleatórias de interesse (tanto observáveis quanto apenas hipoteticamente observáveis), uma especificação de uma distribuição de probabilidade conjunta ou de uma família de possíveis distribuições conjuntas para as variáveis aleatórias observáveis, a identificação de quaisquer parâmetros dessas distribuições que se assumem desconhecidos e possivelmente hipoteticamente observáveis, e (se desejado) uma especificação de uma distribuição conjunta para os parâmetros desconhecidos. Quando tratamos os parâmetros desconhecidos $\theta$ como aleatórios, então a distribuição de probabilidade conjunta das variáveis aleatórias observáveis indexada por $\theta$ é entendida como a distribuição condicional das variáveis aleatórias observáveis dado $\theta$.

\vspace{1cm}
No Exemplo 7.1.1, as variáveis aleatórias observáveis de interesse formam a sequência $X_1, X_2, \dots$, enquanto a taxa de falha $\theta$ é hipoteticamente observável. A família de possíveis distribuições conjuntas de $X_1, X_2, \dots$ é indexada pelo parâmetro $\theta$. A distribuição de probabilidade conjunta das observáveis correspondente ao valor $\theta$ é aquela em que $X_1, X_2, \dots$ são variáveis aleatórias i.i.d. cada uma com distribuição exponencial com parâmetro $\theta$. Esta também é a distribuição condicional de $X_1, X_2, \dots$ dado $\theta$ porque estamos tratando $\theta$ como uma variável aleatória. A distribuição de $\theta$ é a distribuição gama com parâmetros 1 e 2.

\vspace{1cm}
\noindent\textbf{Nota: Redefinindo Ideias Antigas.} O leitor notará que um modelo estatístico nada mais é do que uma formalização de muitas características que temos usado em vários exemplos ao longo dos capítulos anteriores deste livro. Alguns exemplos precisam apenas de algumas das características que compõem a especificação completa de um modelo estatístico, enquanto outros exemplos usam a especificação completa. Nas Seções 7.1–7.4, nós vamos introduzir uma quantidade considerável de terminologia, grande parte da qual é a formalização de conceitos que foram introduzidos e usados em vários lugares anteriormente no livro. O propósito de toda essa formalidade é nos ajudar a manter os conceitos organizados para que possamos dizer quando estamos aplicando as mesmas ideias de novas maneiras e quando estamos introduzindo novas ideias.

Estamos agora prontos para introduzir formalmente a inferência estatística.

\vspace{1cm}
\noindent\textbf{Definição 7.1.2} \quad \textbf{Inferência Estatística.} Uma \textit{inferência estatística} é um procedimento que produz uma declaração probabilística sobre alguns ou todas as partes de um modelo estatístico.

\vspace{1cm}
Por uma ``declaração probabilística'', queremos dizer uma declaração que faz uso de qualquer um dos conceitos de teoria da probabilidade que foram discutidos no texto ou que ainda serão discutidos mais tarde. Por exemplo, eles incluem uma média, uma média condicional, um quantil, uma variância, uma distribuição condicional de uma variável aleatória dada outra, a probabilidade de um evento, uma probabilidade condicional de um evento dado algum outro, e assim por diante. No Exemplo 7.1.1, aqui estão alguns exemplos de inferências estatísticas que alguém poderia querer fazer:
\begin{itemize}
    \item Produzir uma variável aleatória $Y$ (uma função de $X_1, \dots, X_m$) tal que $\Pr(Y \ge \theta|\theta) = 0.9$.
    \item Produzir uma variável aleatória $Y$ que se espera que esteja próxima de $\theta$.
    \item Computar quão provável é que a média dos próximos 10 tempos de vida, $\frac{1}{10}\sum_{i=m+1}^{m+10}X_i$, seja pelo menos 2.
    \item Dizer algo sobre quão confiantes estamos de que $\theta \le 0.4$ após observar $X_1, \dots, X_m$.
\end{itemize}

Todos esses tipos de inferência e outros serão discutidos com mais detalhes neste livro.

Na Definição 7.1.1, distinguimos entre variáveis aleatórias observáveis e hipoteticamente observáveis. Reservamos o nome \textit{observável} para uma variável aleatória que temos certeza de que poderíamos observar se dedicássemos o esforço necessário para observá-la. O nome \textit{hipoteticamente observável} foi usado para uma variável aleatória que exigiria recursos infinitos para ser observada, como o limite (quando $n \to \infty$) das médias amostrais das primeiras $n$ observáveis. Neste texto, tal variável aleatória hipoteticamente observável corresponderá aos parâmetros da distribuição conjunta dos observáveis como no Exemplo 7.1.1. Como esses parâmetros figuram de forma proeminente em muitos dos tipos de problemas de inferência que veremos, vale a pena formalizar o conceito de parâmetro.

\vspace{1cm}
\noindent\textbf{Definição 7.1.3} \quad \textbf{Parâmetro/Espaço de parâmetros.} Em um problema de inferência estatística, uma característica ou combinação de características que determina a distribuição conjunta para as variáveis aleatórias de interesse é chamada de \textit{parâmetro} da distribuição. O conjunto $\Omega$ de todos os valores possíveis de um parâmetro $\theta$ ou de um vetor de parâmetros $(\theta_1, \dots, \theta_k)$ é chamado de \textit{espaço de parâmetros}.

\vspace{1cm}
Todas as famílias de distribuições introduzidas anteriormente (e a serem introduzidas mais tarde) neste livro têm parâmetros que estão incluídos nos nomes dos membros individuais da família. Por exemplo, a família de distribuições binomiais tem parâmetros que chamamos de $n$ e $p$, a família de distribuições normais é parametrizada pela média $\mu$ e variância $\sigma^2$ de cada distribuição, a família de distribuições uniformes em intervalos é parametrizada pelos extremos dos intervalos, a família de distribuições exponenciais é parametrizada pela taxa de parâmetro $\theta$, e assim por diante. No Exemplo 7.1.1, o parâmetro $\theta$ (a taxa de falha) deve ser positivo. Portanto, a menos que certos valores positivos de $\theta$ possam ser explicitamente descartados como valores possíveis de $\theta$, o espaço de parâmetros $\Omega$ será o conjunto de todos os números positivos. Como outro exemplo, suponha que a distribuição das alturas dos indivíduos em uma certa população seja assumida como a distribuição normal com média $\mu$ e variância $\sigma^2$, mas que os valores exatos de $\mu$ e $\sigma^2$ sejam desconhecidos. A média $\mu$ e a variância $\sigma^2$ determinam a distribuição normal particular para as alturas dos indivíduos. Assim, $(\mu, \sigma^2)$ pode ser considerado um par de parâmetros. Neste exemplo de alturas, tanto $\mu$ quanto $\sigma^2$ devem ser positivos. Portanto, o espaço de parâmetros $\Omega$ pode ser considerado como o conjunto de todos os pares $(\mu, \sigma^2)$ tais que $\mu > 0$ e $\sigma^2 > 0$. Se a distribuição normal neste exemplo representa a distribuição das alturas em polegadas dos indivíduos nesta população particular, podemos ter certeza de que $30 < \mu < 100$ e $\sigma^2 < 50$. Nesse caso, o espaço de parâmetros $\Omega$ poderia ser considerado como o conjunto menor de todos os pares $(\mu, \sigma^2)$ tais que $30 < \mu < 100$ e $0 < \sigma^2 < 50$.

A característica importante do espaço de parâmetros $\Omega$ é que ele deve conter todos os valores possíveis dos parâmetros em um dado problema, para que possamos ter certeza de que o valor real do vetor de parâmetros é um ponto em $\Omega$.

\vspace{1cm}
\noindent\textbf{Exemplo 7.1.2} \quad \textbf{Um Ensaio Clínico.} Suponha que 40 pacientes receberão um tratamento para uma condição e que observaremos para cada paciente se ele se recupera ou não da condição. Podemos também estar interessados em uma grande coleção de pacientes adicionais que receberão o mesmo tratamento. Para ser específico, para cada paciente $i = 1, 2, \dots$, seja $X_i = 1$ se o paciente $i$ se recuperar, e seja $X_i = 0$ se não. Como uma coleção de possíveis distribuições para $X_1, X_2, \dots$, poderíamos escolher dizer que os $X_i$ são i.i.d. tendo a distribuição de Bernoulli com parâmetro $p$ para $0 \le p \le 1$. Neste caso, o parâmetro $p$ é conhecido por estar no intervalo $[0, 1]$, e este intervalo poderia ser considerado o espaço de parâmetros. Note também que a lei dos grandes números (Teorema 6.2.4) diz que $p$ é o limite, quando $n$ tende ao infinito, da proporção dos primeiros $n$ pacientes que se recuperam.

\vspace{1cm}
Na maioria dos problemas, existe uma interpretação natural para o parâmetro como uma característica de possíveis distribuições de nossos dados. No Exemplo 7.1.2, o parâmetro $p$ tem uma interpretação natural como a proporção de nossa população de pacientes que se recupera do tratamento. No Exemplo 7.1.1, o parâmetro $\theta$ tem uma interpretação natural como uma taxa de falha, ou seja, um sobre o tempo de vida médio de uma grande população de tempos de vida. Tais casos, inferência sobre parâmetros pode ser interpretada como inferência sobre as características que o parâmetro representa. Neste texto, todos os parâmetros terão tais interpretações naturais. Em exemplos que se encontram fora de um curso introdutório, as interpretações podem não ser tão diretas.

\subsection*{Exemplos de Inferência Estatística}
Aqui estão alguns dos exemplos de modelos estatísticos e inferências que foram introduzidos anteriormente no texto.

\vspace{1cm}
\noindent\textbf{Exemplo 7.1.3} \quad \textbf{Um Ensaio Clínico.} O ensaio clínico introduzido no Exemplo 2.1.4 estava preocupado com a probabilidade de os pacientes evitarem uma recaída enquanto recebiam vários tratamentos. Para cada $i$, seja $X_i=1$ se o paciente $i$ no tratamento com imipramina evitar a recaída e $X_i=0$ caso contrário. Seja $P$ a proporção de pacientes que evitam a recaída em um grande grupo recebendo tratamento com imipramina. Se $P$ for desconhecido, podemos modelar $X_1, X_2, \dots$ como i.i.d. variáveis aleatórias de Bernoulli com parâmetro $p$ condicional a $P=p$. Os pacientes na coluna da imipramina da Tabela 2.1 devem nos fornecer alguma informação que mude nossa incerteza sobre $P$. Uma inferência estatística consistiria em fazer uma declaração de probabilidade sobre os dados e/ou $P$, e o que os dados e $P$ nos dizem um sobre o outro. Por exemplo, no Exemplo 4.7.8, assumimos que $P$ tinha a distribuição uniforme no intervalo $[0,1]$, e encontramos a distribuição condicional de $P$ dados os resultados observados do estudo. Também calculamos a média condicional de $P$ dados os resultados do estudo, bem como o E.M.Q. (Erro Médio Quadrático) para prever $P$ tanto antes quanto depois de observar os resultados do estudo.

\vspace{1cm}
\noindent\textbf{Exemplo 7.1.4} \quad \textbf{Partículas Radioativas.} No Exemplo 5.7.8, partículas radioativas atingem um alvo de acordo com um processo de Poisson com taxa desconhecida $\beta$. No Exercício 22 da Seção 5.7, foi solicitado que você encontrasse a distribuição condicional de $\beta$ após observar o processo de Poisson por um certo período de tempo.

\vspace{1cm}
\noindent\textbf{Exemplo 7.1.5} \quad \textbf{Antropometria de Besouros Pulga.} No Exemplo 5.10.2, plotamos duas medidas físicas de uma amostra de 31 besouros pulga juntamente com contornos de uma distribuição normal bivariada. A família de distribuições normais bivariadas é parametrizada por cinco quantidades: as duas médias, as duas variâncias e a correlação. A escolha de qual conjunto desses cinco parâmetros usar para os dados ajustados é uma forma de inferência estatística conhecida como \textit{estimação}.

\vspace{1cm}
\noindent\textbf{Exemplo 7.1.6} \quad \textbf{Intervalo para a Média.} Suponha que as alturas dos homens em uma certa população sigam a distribuição normal com média $\mu$ e variância 9, como no Exemplo 5.6.7. Desta vez, assuma que não conhecemos o valor da média $\mu$, mas desejamos aprender sobre ela amostrando da população. Suponha que decidamos amostrar $n=36$ homens e seja $\bar{X}_n$ a média de suas alturas. Então o intervalo $(\bar{X}_n - 0.98, \bar{X}_n + 0.98)$ calculado no Exemplo 5.6.8 tem a propriedade de que conterá o valor de $\mu$ com probabilidade 0.95.

\vspace{1cm}
\noindent\textbf{Exemplo 7.1.7} \quad \textbf{Discriminação na Seleção do Júri.} No Exemplo 5.8.4, estávamos interessados em saber se havia evidência de discriminação contra Mexicano-Americanos na seleção do júri. A Figura 5.8 mostra como pessoas que entraram no caso com diferentes opiniões sobre a extensão da discriminação (se houver) poderiam alterar suas opiniões à luz do aprendizado da evidência numérica apresentada no caso.

\vspace{1cm}
\noindent\textbf{Exemplo 7.1.8} \quad \textbf{Tempos de Serviço em uma Fila.} Suponha que clientes em uma fila devam esperar por serviço e que estamos interessados em observar os tempos de serviço de vários clientes. Suponha que estejamos interessados na taxa em que os clientes são atendidos. Seja $Z$ a taxa de serviço, e no Exemplo 5.7.4, mostramos como encontrar a distribuição condicional de $Z$ dados vários tempos de serviço observados.

\subsection*{Classes Gerais de Problemas de Inferência}

\textbf{Previsão.} Uma forma de inferência é tentar prever variáveis aleatórias que ainda não foram observadas. No Exemplo 7.1.1, podemos estar interessados na média dos próximos 10 tempos de vida, $\frac{1}{10}\sum_{i=m+1}^{m+10} X_i$. No exemplo do ensaio clínico (Exemplo 7.1.3), podemos estar interessados em quantos pacientes no grupo da imipramina terão sucesso. Em praticamente todo problema de inferência estatística em que não observamos todos os dados relevantes, a previsão é possível. Quando a quantidade não observada a ser prevista é um parâmetro, a previsão é geralmente chamada de \textit{estimação}, como no Exemplo 7.1.5.

\vspace{0.5cm}
\noindent\textbf{Problemas de Decisão Estatística.} Em muitos problemas de inferência estatística, após a análise de dados experimentais, devemos escolher entre várias decisões de classes com a propriedade de que as consequências de cada decisão disponível dependem do valor desconhecido de algum parâmetro. Por exemplo, podemos ter que estimar a taxa de falha $\theta$ de nossos componentes eletrônicos quando as consequências dependem de quão próxima nossa estimativa de $\theta$ está do valor correto. Como outro exemplo, podemos ter que decidir se a proporção desconhecida $P$ de pacientes no exemplo da imipramina (Exemplo 7.1.3) é maior ou menor que uma constante especificada quando as consequências dependem de onde $P$ se encontra em relação à constante. Este último tipo de inferência está intimamente relacionado a \textit{testes de hipóteses}, o assunto do Capítulo 9.

\vspace{0.5cm}
\noindent\textbf{Delineamento Experimental.} Em alguns problemas de inferência estatística, temos algum controle sobre o tipo ou a quantidade de dados experimentais que serão coletados. Por exemplo, considere um experimento para determinar a resistência média à tração de um certo tipo de liga como uma função da pressão e temperatura em que a liga é produzida. Dentro dos limites de certos orçamentos e restrições de tempo, pode ser possível para o experimentador escolher os níveis de pressão e temperatura nos quais os espécimes experimentais da liga serão produzidos, e também especificar o número de espécimes a serem produzidos em cada um desses níveis.
Tal problema, no qual o experimentador pode escolher (pelo menos até certo ponto) o delineamento experimental particular a ser realizado, é chamado de problema de \textit{delineamento experimental}. Obviamente, o delineamento de um experimento e a análise estatística dos dados experimentais estão intimamente relacionados. Não se pode projetar um experimento eficaz sem considerar a análise estatística subsequente que será realizada nos dados que serão obtidos. E não se pode realizar uma análise estatística significativa de dados experimentais sem considerar o delineamento experimental particular do qual os dados foram derivados.

\vspace{0.5cm}
\noindent\textbf{Outras Inferências.} As classes gerais de problemas descritas acima, bem como os exemplos mais específicos que apareceram anteriormente, pretendem ser ilustrações de tipos de inferências estatísticas que poderemos realizar com a teoria e métodos introduzidos neste texto. A gama de possíveis modelos, inferências e métodos que podem surgir quando os dados são observados em problemas de pesquisa reais excede em muito o que podemos introduzir aqui. Espera-se que, ao obter uma compreensão dos problemas que cobrimos aqui, o leitor terá uma apreciação do que precisa ser feito quando um problema estatístico mais desafiador surge.

\subsection*{Definição de uma Estatística}
\noindent\textbf{Exemplo 7.1.9} \quad \textbf{Tempos de Falha de Rolamentos de Esferas.} No Exemplo 5.6.9, tínhamos uma amostra dos números de milhões de revoluções antes da falha para 23 rolamentos de esferas. Modelamos os tempos de vida como uma amostra aleatória de uma distribuição lognormal. Podemos supor que os parâmetros $\mu$ e $\sigma^2$ dessa distribuição lognormal são desconhecidos e que talvez queiramos fazer alguma inferência sobre eles. Gostaríamos de fazer uso dos 23 valores observados para fazer qualquer inferência. Mas precisamos acompanhar todos os 23 valores ou existem alguns resumos dos dados sobre os quais nossa inferência será baseada?

\vspace{1cm}
Cada inferência estatística que aprenderemos a realizar neste livro será baseada em um ou alguns resumos dos dados disponíveis. Tais resumos de dados surgem com tanta frequência e são tão fundamentais para a inferência que recebem um nome especial.

\vspace{1cm}
\noindent\textbf{Definição 7.1.4} \quad \textbf{Estatística.} Suponha que as variáveis aleatórias observáveis de interesse sejam $X_1, \dots, X_n$. Seja $r$ uma função de valor real arbitrária de $n$ variáveis reais. Então a variável aleatória $T = r(X_1, \dots, X_n)$ é chamada de \textit{estatística}.

\vspace{1cm}
Três exemplos de estatísticas são a média amostral $\bar{X}_n$, o máximo $Y_n$ dos valores de $X_1, \dots, X_n$, e a função $r(X_1, \dots, X_n)$, que tem o valor constante 3 para todos os valores de $X_1, \dots, X_n$.

\vspace{1cm}
\noindent\textbf{Exemplo 7.1.10} \quad \textbf{Tempos de Falha de Rolamentos de Esferas.} No Exemplo 7.1.9, suponha que estivéssemos interessados em fazer uma declaração sobre quão longe $\mu$ está de 40. Então, poderíamos querer usar a estatística
$$ T = \left| \frac{1}{36}\sum_{i=1}^{36}\log(X_i) - 4 \right| $$
em nosso procedimento de inferência. Neste caso, $T$ é uma medida ingênua de quão longe os dados sugerem que $\mu$ está de 40.

\vspace{1cm}
\noindent\textbf{Exemplo 7.1.11} \quad \textbf{Intervalo para a Média.} No Exemplo 7.1.6, construímos um intervalo que tem probabilidade 0.95 de conter $\mu$. Os extremos do intervalo, a saber, $\bar{X}_n - 0.98$ e $\bar{X}_n + 0.98$, são estatísticas.

\vspace{1cm}
Muitas inferências podem prosseguir sem construir estatísticas explicitamente como um passo preliminar. No entanto, a maioria das inferências envolverá o uso de estatísticas que poderiam ser identificadas antecipadamente. E saber quais estatísticas são úteis em quais circunstâncias pode simplificar muito a inferência. Expressar uma inferência em termos de uma estatística também pode nos ajudar a decidir quão bem a inferência atende às nossas necessidades. Por exemplo, no Exemplo 7.1.10, se estimamos $\mu-40$ por $T$, podemos usar a distribuição de $T$ para nos ajudar a determinar quão provavelmente é que $T$ difira de $|\mu-40|$ por uma grande quantidade. À medida que construímos inferências específicas mais tarde neste livro, chamaremos a atenção para aquelas estatísticas que desempenham papéis importantes na inferência.

\subsection*{Parâmetros como Variáveis Aleatórias}
Há alguma controvérsia sobre se os parâmetros devem ser tratados como variáveis aleatórias ou meramente como números que indexam uma distribuição. Por exemplo, no Exemplo 7.1.3, seja $P$ a proporção de pacientes que evitam a recaída em um grande grupo que recebe imipramina. Então, dizemos que $X_1, X_2, \dots$ são i.i.d. variáveis aleatórias de Bernoulli com parâmetro $p$ condicional a $P=p$. Estamos explicitamente pensando em $P$ como uma variável aleatória, e damos a ele uma distribuição. Uma alternativa seria dizer que $X_1, X_2, \dots$ são i.i.d. variáveis aleatórias de Bernoulli com parâmetro $p$ onde $p$ é desconhecido e deixar por isso mesmo.
Se realmente queremos calcular algo como a probabilidade condicional de que a proporção de pacientes seja maior que 0.5 dados os resultados dos primeiros 40 pacientes, então devemos tratar $P$ como uma variável aleatória. Por outro lado, se estamos apenas interessados em fazer declarações de probabilidade que são indexadas pelo valor de $p$, então não precisamos pensar em $p$ como uma variável aleatória. Por exemplo, podemos desejar encontrar duas variáveis aleatórias $Y_1$ e $Y_2$ (funções de $X_1, \dots, X_{40}$) tais que, não importa qual $p$ seja, a probabilidade de que $Y_1 \le p \le Y_2$ seja de pelo menos 0.9. Algumas das inferências que discutiremos mais adiante neste livro são do primeiro tipo que requerem o tratamento de $P$ como uma variável aleatória, e algumas são do último tipo em que $p$ é meramente um índice para uma distribuição.

\vspace{0.5cm}
Alguns estatísticos acreditam que é possível e útil tratar parâmetros como variáveis aleatórias em todos os problemas de inferência estatística. Eles acreditam que a distribuição de um parâmetro é uma probabilidade subjetiva que representa as crenças subjetivas e informadas de um experimentador individual sobre onde o valor verdadeiro do parâmetro provavelmente está. Uma vez que eles atribuem uma distribuição a um parâmetro, essa distribuição não é diferente de qualquer outra distribuição de probabilidade usada no campo da estatística, e todas as regras da teoria da probabilidade se aplicam a cada distribuição. De fato, em todos os casos descritos neste livro, os parâmetros podem realmente ser identificados como limites de funções de grandes coleções de observações potenciais. Aqui está um exemplo típico.

\vspace{1cm}
\noindent\textbf{Exemplo 7.1.12} \quad \textbf{Parâmetro como um Limite de Variáveis Aleatórias.} No Exemplo 7.1.3, o parâmetro $P$ pode ser entendido da seguinte forma: Imagine uma sequência infinita de pacientes potenciais recebendo tratamento com imipramina. Suponha que, para cada inteiro $n$, os resultados de cada subconjunto ordenado de $n$ pacientes dessa sequência infinita tenham a mesma distribuição conjunta que os resultados de qualquer outro subconjunto ordenado de $n$ pacientes. Em outras palavras, suponha que a ordem em que os pacientes aparecem na sequência seja irrelevante para o resultado do tratamento. Seja $P_n$ a proporção de pacientes que não recaem entre os primeiros $n$ pacientes. Pode-se mostrar que a probabilidade é 1 de que $P_n$ convirja para algo quando $n \to \infty$. Essa algo pode ser pensado como $P$, o que tem sido chamado de proporção de sucessos em uma população muito grande. Nesse sentido, $P$ é uma variável aleatória porque é uma função de outros modelos de variáveis aleatórias. Um argumento semelhante pode ser feito em todos os modelos estatísticos deste livro, envolvendo parâmetros, mas a matemática necessária para tornar esses argumentos precisos é muito avançada para ser apresentada aqui (o Capítulo 12 de Schervish (1995) contém os detalhes necessários). Estatísticos que argumentam desta forma são ditos aderir à filosofia Bayesiana de estatística e são chamados de \textit{Bayesianos}.

\vspace{0.5cm}
Há outra linha de raciocínio que leva naturalmente a tratar $P$ como uma variável aleatória no Exemplo 7.1.12 sem depender de uma sequência infinita de pacientes potenciais. Suponha que o número de pacientes potenciais, embora grande, seja finito, digamos $N$. Então podemos fazer a aproximação na Seção 5.3.4 aplicável. Então $P$ é apenas a proporção de sucessos entre a grande população de $N$ pacientes. Condicional a $P=p$, o número de sucessos em uma amostra de $n$ pacientes será aproximadamente uma variável aleatória binomial com parâmetros $n$ e $p$ de acordo com o Teorema 5.3.4. Se os resultados dos pacientes na amostra são variáveis aleatórias, entre outras coisas, então a proporção de sucessos entre eles também é uma variável aleatória.
Há outro grupo de estatísticos que acredita que em muitos problemas não é apropriado atribuir uma distribuição a um parâmetro, mas em vez disso, afirma que o valor verdadeiro do parâmetro é um certo número fixo cujo valor por acaso é desconhecido para o experimentador. Esses estatísticos atribuem uma distribuição a um parâmetro apenas quando há extensa informação prévia sobre as frequências relativas com que parâmetros similares tomaram cada um de seus valores possíveis em experimentos passados. Se dois cientistas diferentes pudessem concordar sobre quais experimentos passados eram similares ao experimento atual, então eles poderiam concordar sobre uma distribuição a ser atribuída ao parâmetro. Por exemplo, suponha que a proporção $\theta$ de itens defeituosos em um grande lote manufaturado seja desconhecida. Suponha também que o mesmo fabricante produziu muitos desses lotes de itens no passado e que registros detalhados foram mantidos sobre as proporções de itens defeituosos em lotes passados. As frequências relativas para lotes passados poderiam então ser usadas para construir uma distribuição para $\theta$. Estatísticos que argumentariam desta forma são ditos aderir à filosofia frequentista de estatística e são chamados de \textit{frequentistas}.

\vspace{0.5cm}
Os frequentistas baseiam-se na suposição de que existem sequências infinitas de variáveis aleatórias para dar sentido à maioria de suas declarações de probabilidade. Uma vez que se assume a existência de tal sequência infinita, descobre-se que os parâmetros das distribuições que estão sendo usadas são limites de funções das sequências infinitas, assim como fazem os Bayesianos descritos acima. Desta forma, os parâmetros são variáveis aleatórias porque são funções de outras variáveis aleatórias. O ponto de desacordo entre os dois grupos é se é útil ou mesmo possível atribuir uma distribuição a tais parâmetros.

\vspace{0.5cm}
Tanto Bayesianos quanto frequentistas concordam sobre a utilidade de famílias de distribuições para observações indexadas por parâmetros. Os Bayesianos referem-se à distribuição indexada pelo valor do parâmetro $\theta$ como a distribuição condicional das observações dado que o parâmetro é igual a $\theta$. Os frequentistas referem-se à distribuição indexada por $\theta$ como a distribuição das observações quando $\theta$ é o valor verdadeiro do parâmetro. Os dois grupos concordam que sempre que uma distribuição pode ser atribuída a um parâmetro, a teoria e os métodos a serem descritos neste capítulo são aplicáveis e úteis. Nas Seções 7.2–7.4, nós explicitamente assumiremos que cada parâmetro é uma variável aleatória e atribuiremos a ele uma distribuição que representa as probabilidades de que o parâmetro esteja em vários subconjuntos do espaço de parâmetros. A partir da Seção 7.5, consideraremos técnicas de estimação que não se baseiam na atribuição de distribuições a parâmetros.
